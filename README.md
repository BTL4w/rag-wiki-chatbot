# RAG Wiki Chatbot

Há»‡ thá»‘ng chatbot QA (Question Answering) sá»­ dá»¥ng Retrieval-Augmented Generation (RAG) vá»›i nguá»“n dá»¯ liá»‡u tá»« Wikipedia tiáº¿ng Viá»‡t.

## ğŸ¯ Tá»•ng quan

Dá»± Ã¡n nÃ y xÃ¢y dá»±ng má»™t há»‡ thá»‘ng há»i Ä‘Ã¡p thÃ´ng minh dá»±a trÃªn:
- **Retrieval**: TÃ¬m kiáº¿m thÃ´ng tin liÃªn quan tá»« Wikipedia
- **Augmented**: Bá»• sung ngá»¯ cáº£nh tá»« tÃ i liá»‡u tÃ¬m Ä‘Æ°á»£c
- **Generation**: Sinh cÃ¢u tráº£ lá»i báº±ng LLM (Large Language Model)

### âœ¨ TÃ­nh nÄƒng ná»•i báº­t

- âœ… **Multi-topic support**: Download vÃ  xÃ¢y dá»±ng knowledge base tá»« nhiá»u chá»§ Ä‘á»
- âœ… **Hybrid search**: Káº¿t há»£p Dense (semantic) vÃ  BM25 (keyword) search
- âœ… **Reranking**: Sá»­ dá»¥ng Cross-Encoder Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c
- âœ… **Multi-LLM support**: OpenAI, Gemini, Anthropic
- âœ… **Source citation**: TrÃ­ch dáº«n nguá»“n Wikipedia vá»›i URL Ä‘áº§y Ä‘á»§
- âœ… **Caching**: Tá»± Ä‘á»™ng cache embeddings Ä‘á»ƒ tá»‘i Æ°u hiá»‡u suáº¥t

## ğŸ“ Kiáº¿n trÃºc

```
Query â†’ Embedding â†’ Vector Search â†’ Reranking â†’ LLM Generation â†’ Answer + Sources
                     â†“
                  Wikipedia
                  Knowledge Base
```

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
rag_wiki/
â”œâ”€â”€ README.md                    # File nÃ y
â”œâ”€â”€ PHAN_TICH_COMPONENT.md       # PhÃ¢n tÃ­ch chi tiáº¿t tá»«ng component
â”œâ”€â”€ requirements.txt             # CÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
â”œâ”€â”€ run_pipeline.py              # Cháº¡y toÃ n bá»™ pipeline
â”œâ”€â”€ .env                         # API keys 
â”‚
â”œâ”€â”€ data/                        # Dá»¯ liá»‡u
â”‚   â”œâ”€â”€ raw_wiki/               # Wikipedia dump gá»‘c
â”‚   â”œâ”€â”€ parsed/                 # VÄƒn báº£n Ä‘Ã£ parse
â”‚   â”œâ”€â”€ chunks/                 # Chunks + embeddings
â”‚   â”œâ”€â”€ faiss_index/            # Vector database
â”‚   â””â”€â”€ .embedding_cache/       # Cache embeddings
â”‚
â”œâ”€â”€ scripts/                     # ETL Scripts
â”‚   â”œâ”€â”€ download_wiki.py        # Táº£i Wikipedia
â”‚   â”œâ”€â”€ parse_wikitext.py       # Parse wikitext
â”‚   â””â”€â”€ chunk_text.py           # Chia thÃ nh chunks
â”‚
â”œâ”€â”€ src/                        # Source code chÃ­nh
â”‚   â”œâ”€â”€ config.yaml             # Cáº¥u hÃ¬nh há»‡ thá»‘ng
â”‚   â”œâ”€â”€ qa_pipeline.py          # Pipeline chÃ­nh
â”‚   â”œâ”€â”€ indexer/                # Embedding & indexing
â”‚   â”‚   â”œâ”€â”€ embedder.py
â”‚   â”‚   â””â”€â”€ indexer.py
â”‚   â”œâ”€â”€ retriever/              # Retrieval & reranking
â”‚   â”‚   â”œâ”€â”€ retriever.py
â”‚   â”‚   â””â”€â”€ reranker.py
â”‚   â””â”€â”€ generator/              # LLM generation
â”‚       â”œâ”€â”€ generator.py
â”‚       â””â”€â”€ prompt_templates.md
â”‚
â””â”€â”€ notebooks/                   # Jupyter notebooks demo
```

## ğŸš€ Quickstart

### 1. YÃªu cáº§u há»‡ thá»‘ng

- Python 3.8+
- 8GB RAM (tá»‘i thiá»ƒu)
- 10GB dung lÆ°á»£ng á»• Ä‘Ä©a

### 2. CÃ i Ä‘áº·t

```bash
# Clone repo
git clone https://github.com/BTL4w/rag-wiki-chatbot.git
cd rag_wiki

# CÃ i Ä‘áº·t thÆ° viá»‡n
pip install -r requirements.txt
```

### 3. Cáº¥u hÃ¬nh API Keys

Táº¡o file `.env` trong thÆ° má»¥c gá»‘c:

```env
# Chá»n má»™t trong cÃ¡c LLM providers
OPENAI_API_KEY=your_openai_key_here
# hoáº·c
GEMINI_API_KEY=your_gemini_key_here
# hoáº·c
ANTHROPIC_API_KEY=your_anthropic_key_here
```

### 4. Download & Build Knowledge Base

**Option 1: Cháº¡y toÃ n bá»™ pipeline (Khuyáº¿n nghá»‹)**

```bash
# Download 50 bÃ i vá» AI vÃ  cháº¡y toÃ n bá»™ pipeline
python run_pipeline.py --topic "artificial intelligence machine learning" --limit 50
```

**Option 2: Cháº¡y tá»«ng bÆ°á»›c**

```bash
# BÆ°á»›c 1: Download Wikipedia
python scripts/download_wiki.py --topic "artificial intelligence" --limit 50

# BÆ°á»›c 2: Parse vÄƒn báº£n
python scripts/parse_wikitext.py

# BÆ°á»›c 3: Chia thÃ nh chunks
python scripts/chunk_text.py

# BÆ°á»›c 4: Táº¡o embeddings
python -m src.indexer.embedder --input data/chunks/chunks.jsonl --output data/chunks/embeddings.npy

# BÆ°á»›c 5: Build vector index
python -m src.indexer.indexer --embeddings data/chunks/embeddings.npy --chunks data/chunks/chunks.jsonl
```

### 5. Cháº¡y Chatbot

**Mode Interactive**:

```bash
python -m src.qa_pipeline
```

**Mode Single Question**:

```bash
python -m src.qa_pipeline --question "Há»c mÃ¡y lÃ  gÃ¬?"
```

**Output máº«u**:

```
ğŸ’¬ Báº¡n: Há»c mÃ¡y lÃ  gÃ¬?

ğŸ¤– Bot: Há»c mÃ¡y hay mÃ¡y há»c (machine learning) lÃ  má»™t lÄ©nh vá»±c cá»§a trÃ­ tuá»‡ nhÃ¢n táº¡o 
liÃªn quan Ä‘áº¿n viá»‡c nghiÃªn cá»©u vÃ  xÃ¢y dá»±ng cÃ¡c kÄ© thuáº­t cho phÃ©p cÃ¡c há»‡ thá»‘ng "há»c" 
tá»± Ä‘á»™ng tá»« dá»¯ liá»‡u Ä‘á»ƒ giáº£i quyáº¿t nhá»¯ng váº¥n Ä‘á» cá»¥ thá»ƒ (Nguá»“n: [1]).

ğŸ“š Nguá»“n (5):
  [1] Há»c mÃ¡y - Introduction
      ğŸ”— https://vi.wikipedia.org/wiki/Há»c_mÃ¡y
  [2] TrÃ­ tuá»‡ nhÃ¢n táº¡o - Há»c há»i
      ğŸ”— https://vi.wikipedia.org/wiki/TrÃ­_tuá»‡_nhÃ¢n_táº¡o
  [3] Há»c mÃ¡y - TÃ­nh phá»• quÃ¡t
      ğŸ”— https://vi.wikipedia.org/wiki/Há»c_mÃ¡y

â±ï¸ Thá»i gian: 1.52s
```

## ğŸ“– Sá»­ dá»¥ng trong Code Python

```python
from src import QAPipeline

# Khá»Ÿi táº¡o pipeline
pipeline = QAPipeline("src/config.yaml")
pipeline.load_components()

# Äáº·t cÃ¢u há»i
response = pipeline.query("Thá»§ Ä‘Ã´ cá»§a Viá»‡t Nam lÃ  gÃ¬?")

print(response['answer'])
print(response['sources'])
print(f"Time: {response['total_time']:.2f}s")
```

## âš™ï¸ Cáº¥u hÃ¬nh

### Chá»n Embedding Model

```yaml
# src/config.yaml
embedding:
  provider: "sentence-transformers"
  model_name: "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
  dimension: 768
  batch_size: 32
```

**Models khuyÃªn dÃ¹ng cho tiáº¿ng Viá»‡t**:
- `paraphrase-multilingual-mpnet-base-v2` (768 dim, khuyáº¿n nghá»‹)
- `LaBSE` (768 dim, multilingual)
- OpenAI `text-embedding-3-small` (1536 dim, API)

### Chá»n LLM Provider

```yaml
# src/config.yaml
generation:
  provider: "openai"  # openai, gemini, anthropic
  model_name: "gpt-4o-mini"
  temperature: 0.1
  max_completion_tokens: 500
```

### Tá»‘i Æ°u Retrieval

```yaml
# src/config.yaml
retrieval:
  top_k: 50              # Sá»‘ chunks ban Ä‘áº§u
  final_k: 5             # Sá»‘ chunks sau rerank
  use_reranker: false    # Báº­t/táº¯t reranking
  hybrid_search: false   # Báº­t BM25 + dense search
```

## ğŸ¯ Use Cases

### Use Case 1: Multi-Topic Knowledge Base

```bash
# Download nhiá»u topics
python scripts/download_wiki.py --topic "artificial intelligence" --limit 50
python scripts/download_wiki.py --topic "Viá»‡t Nam" --limit 50
python scripts/download_wiki.py --topic "lá»‹ch sá»­" --limit 30

# Process táº¥t cáº£
python scripts/parse_wikitext.py
python scripts/chunk_text.py
python -m src.indexer.embedder --input data/chunks/chunks.jsonl --output data/chunks/embeddings.npy
python -m src.indexer.indexer --embeddings data/chunks/embeddings.npy --chunks data/chunks/chunks.jsonl

# Chatbot cÃ³ thá»ƒ tráº£ lá»i cáº£ 3 topics!
python -m src.qa_pipeline
```

### Use Case 2: Domain-Specific Chatbot

```bash
# Chá»‰ download vá» Y táº¿
python run_pipeline.py --topic "y táº¿ sá»©c khá»e" --limit 100

# Chatbot chuyÃªn vá» Y táº¿
python -m src.qa_pipeline
```

### Use Case 3: Custom Wikipedia Download

```bash
# Download theo category
python scripts/download_wiki.py --category "Machine learning" --limit 50

# Download specific pages (táº¡o file pages.txt)
python scripts/download_wiki.py --pages-file pages.txt
```

## ğŸ› ï¸ Scripts Tiá»‡n Ãch

### Clean Data

```bash
# Chá»‰ xÃ³a dá»¯ liá»‡u
clean_data.bat

# XÃ³a + cháº¡y láº¡i pipeline
clean_and_retry.bat
```

### Debug Mode

```bash
# Cháº¡y vá»›i debug info
python -m src.qa_pipeline --question "..." --debug
```

Output:
```
ğŸ” Debug:
  Retrieved: 50 chunks
  Reranked: 5 chunks
  Retrieval: 0.050s
  Rerank: 0.200s
  Generation: 1.500s
```



## ğŸ”„ Workflow Tá»•ng QuÃ¡t

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PHASE 1: SETUP (1 láº§n)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚                 â”‚
        â–¼                 â–¼                 â–¼
   Download           Parse             Chunk
   Wikipedia        Wikitext            Text
        â”‚                 â”‚                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                 â–¼                 â–¼
   Create            Build Vector      Save to
   Embeddings          Index            Disk
        â”‚                 â”‚                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PHASE 2: QUERY (má»—i cÃ¢u há»i)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
        User Question     â”‚
              â”‚           â”‚
              â–¼           â–¼
        Embed Query â†’ Vector Search
              â”‚           â”‚
              â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
              Reranking (optional)
                    â”‚
                    â–¼
            Build Context + Prompt
                    â”‚
                    â–¼
              LLM Generate
                    â”‚
                    â–¼
         Answer + Sources + URLs
```



## ğŸ“ Há»c thÃªm

### Concepts chÃ­nh

- **RAG**: Retrieval-Augmented Generation
- **Embedding**: Vector representation of text
- **FAISS**: Vector database for similarity search
- **Cross-Encoder**: Reranking model
- **BM25**: Keyword-based ranking algorithm

### Architecture Patterns

- **Pipeline Pattern**: Data flows through stages
- **Caching Pattern**: Cache expensive operations
- **Multi-provider Pattern**: Swap components easily

